# Strix Configuration
# Copy this file to .env and fill in your values

# LLM Provider Configuration
# Format: provider/model (e.g., openai/gpt-4o, anthropic/claude-3-5-sonnet, zhipu/glm-4)
STRIX_LLM=zhipu/glm-4

# Your API key from the LLM provider
LLM_API_KEY=your-api-key-here

# Optional: Custom API base URL (for local models or proxies)
# LLM_API_BASE=http://localhost:8000/v1

# Optional: Request timeout in seconds (default: 600)
# LLM_TIMEOUT=600
